{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infopath.model_loader import load_model_and_optimizer\n",
    "from infopath.config import load_training_opt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import numpy as np\n",
    "from infopath.utils.functions import load_data, opto, run_with_perturbation, pear_corr, feature_pop_avg, mse_2d\n",
    "from infopath.losses import noise_cross_corr, cross_corr_guillaume, cross_corr_jitter, reorder_model_trials\n",
    "from infopath.train import t_trial_pearson\n",
    "import scipy.sparse as sp\n",
    "from infopath.config import compare_opt\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import os\n",
    "from infopath.losses import trial_matching_loss, hard_trial_matching_loss\n",
    "from geomloss import SamplesLoss\n",
    "from infopath.utils.plot_utils import plot_with_size, strip_right_top_axis\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "font = {\"size\": 6, \"family\":\"arial\"}\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rc(\"font\", **font)\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = {\n",
    "    \"nofb\": \n",
    "    [\n",
    "        \"log_dir/1d74764c4551eef5158418ea67fbe1a5885dfdb1/2024_5_27_9_46_33_teacher_conf_block/\",\n",
    "        \n",
    "        # Full\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_42_nofb_full_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_42_nofb_full_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_45_nofb_full_2\",\n",
    "        \n",
    "        # no sparsity \n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_46_nofb_nosparsity_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_47_nofb_nosparsity_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_47_nofb_nosparsity_2\",\n",
    "        \n",
    "        # with inh across\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_46_nofb_noinhacross_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_46_nofb_noinhacross_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_46_nofb_noinhacross_2\",\n",
    "\n",
    "        # no EI\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_45_nofb_noei_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_46_nofb_noei_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_46_nofb_noei_2\",\n",
    "        \n",
    "        # no tm\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_36_6_nofb_notm_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_5_48_nofb_notm_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_46_19_nofb_notm_2\",\n",
    "\n",
    "        # no spike\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_47_nofb_nospike_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_40_47_nofb_nospike_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_45_nofb_nospike_2\",\n",
    "\n",
    "        # no spike + reset \n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_45_nofb_nospikereset_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_45_nofb_nospikereset_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_45_nofb_nospikereset_2\",\n",
    "\n",
    "        # sigmoid\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_54_nofb_sigmoid_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_54_nofb_sigmoid_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_54_nofb_sigmoid_2\",\n",
    "        ],\n",
    "    \"withfb1\":\n",
    "    [\n",
    "        \"log_dir/1d74764c4551eef5158418ea67fbe1a5885dfdb1/2024_5_27_9_46_33_teacher_conf/\",\n",
    "\n",
    "        # Full\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_44_withfb1_full_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_45_54_withfb1_full_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_46_5_withfb1_full_2\",\n",
    "        \n",
    "        # no sparsity \n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_49_26_withfb1_nosparsity_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_49_38_withfb1_nosparsity_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_2_32_withfb1_nosparsity_2\",\n",
    "\n",
    "        # with inh across\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_46_5_withfb1_noinhacross_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_46_5_withfb1_noinhacross_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_49_25_withfb1_noinhacross_2\",\n",
    "        \n",
    "        # no ei\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_46_5_withfb1_noei_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_44_25_withfb1_noei_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_14_49_36_withfb1_noei_2\",\n",
    "\n",
    "        # no tm\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_2_48_withfb1_notm_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_3_54_withfb1_notm_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_4_31_withfb1_notm_2\",\n",
    "        \n",
    "        # no spike\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_1_30_withfb1_nospike_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_7_46_withfb1_nospike_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_7_46_withfb1_nospike_2\",\n",
    "        \n",
    "        # no spike + reset \n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_54_23_withfb1_nospikereset_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_7_46_withfb1_nospikereset_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_3_42_withfb1_nospikereset_2\",\n",
    "        \n",
    "        # sigmoid\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_6_2_withfb1_sigmoid_0\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_6_30_withfb1_sigmoid_1\",\n",
    "        \"log_dir/4f811b0a7d426989a9069580e0108cc3e5ac7d60/2024_11_12_15_6_40_withfb1_sigmoid_2\",\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_name(log):\n",
    "    if \"teacher\" in log:\n",
    "        return \"base\"\n",
    "    if \"notm\" in log:\n",
    "        return \"No TM\"\n",
    "    if \"noinhacross_noei\" in log:\n",
    "        return \"Non-local inhibition\"\n",
    "    if \"noinhacross\" in log:\n",
    "        return \"Non-local inhibition\"\n",
    "    if \"noei\" in log:\n",
    "        return \"No Dale's law\"\n",
    "    if \"nosparsity\" in log:\n",
    "        return \"No sparsity\"\n",
    "    if \"nospike\" in log:\n",
    "        if \"reset\" in log:\n",
    "            return \"No spike + reset\"\n",
    "        return \"No spike\"\n",
    "    if \"sigmoid\" in log:\n",
    "        return \"Sigmoid\"\n",
    "    return \"Full rec. method\"\n",
    "\n",
    "thr = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infopath.losses import z_score_norm\n",
    "\n",
    "\n",
    "def trial_matched_pearson(model, spikes_nofb, spikes):   \n",
    "    t_trial_nofb, t_trial = feature_pop_avg(\n",
    "        model.filter_fun2(model.filter_fun1(spikes_nofb)),\n",
    "        model.filter_fun2(model.filter_fun1(spikes)),\n",
    "        None,\n",
    "        None,\n",
    "        model.rsnn.area_index,\n",
    "        model.rsnn.excitatory_index,\n",
    "        0,\n",
    "        z_score=model.opt.z_score,\n",
    "    )\n",
    "\n",
    "    t_trial_nofb, t_trial = t_trial_nofb.T, t_trial.T\n",
    "    keep = min(t_trial_nofb.shape[1], t_trial.shape[1])\n",
    "    keep_train = torch.randperm(t_trial_nofb.shape[1])[:keep]\n",
    "    keep_test = torch.randperm(t_trial.shape[1])[:keep]\n",
    "    t_trial_nofb, t_trial = t_trial_nofb[:, keep_train], t_trial[:, keep_test]\n",
    "    cost = mse_2d(t_trial_nofb, t_trial)\n",
    "    keepx, ytox = linear_sum_assignment(cost.detach().cpu().numpy())\n",
    "    t_trial_nofb = t_trial_nofb[:, keepx]\n",
    "    t_trial = t_trial[:, ytox]\n",
    "    return pear_corr(t_trial.T, t_trial_nofb.T), t_trial_nofb, t_trial, torch.nn.MSELoss()(t_trial_nofb, t_trial).item()\n",
    "\n",
    "def neuron_loss(model, spikes_nofb, spikes):\n",
    "    psth_nofb = model.filter_fun1(spikes_nofb)\n",
    "    psth = model.filter_fun1(spikes)\n",
    "    psth_nofb, psth,_ = z_score_norm(psth_nofb, psth)\n",
    "    return ((psth_nofb.T - psth.T)**2).mean(1).cpu()\n",
    "\n",
    "def trial_matched_mse(model, spikes_nofb, spikes):   \n",
    "    idx = model.rsnn.area_index > -1\n",
    "    filt_data = model.filter_fun2(model.filter_fun1(spikes_nofb))[:,:,idx]\n",
    "    filt_model = model.filter_fun2(model.filter_fun1(spikes))[:,:,idx]\n",
    "    t_trial_nofb, t_trial = feature_pop_avg(\n",
    "        filt_data,\n",
    "        filt_model,\n",
    "        None,\n",
    "        None,\n",
    "        model.rsnn.area_index[idx],\n",
    "        model.rsnn.excitatory_index[idx],\n",
    "        0,\n",
    "        z_score=model.opt.z_score,\n",
    "    )\n",
    "    t_trial_nofb, t_trial = t_trial_nofb.T, t_trial.T\n",
    "    keep = min(t_trial_nofb.shape[1], t_trial.shape[1])\n",
    "    keep_train = torch.randperm(t_trial_nofb.shape[1])[:keep]\n",
    "    keep_test = torch.randperm(t_trial.shape[1])[:keep]\n",
    "    t_trial_nofb, t_trial = t_trial_nofb[:, keep_train], t_trial[:, keep_test]\n",
    "    with torch.no_grad():\n",
    "        cost = mse_2d(t_trial, t_trial_nofb)\n",
    "        keepx, ytox = linear_sum_assignment(cost.detach().cpu().numpy())\n",
    "    t_trial = t_trial[:, keepx]\n",
    "    t_trial_nofb = t_trial_nofb[:, ytox]\n",
    "    return ((t_trial.T - t_trial_nofb.T)**2).mean(1).cpu(), t_trial_nofb, t_trial, torch.nn.MSELoss()(t_trial_nofb, t_trial).item()\n",
    "\n",
    "# 95% confidence interval of bernoulli variable\n",
    "def confidence_interval(p, n):\n",
    "    return 1.96 * np.sqrt(p * (1-p) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base (tensor([0, 3], device='cuda:0'), tensor([ 928, 1021], device='cuda:0'))\n",
      "Full rec. method (tensor([0, 3], device='cuda:0'), tensor([1068,  865], device='cuda:0'))\n",
      "Full rec. method (tensor([0, 3], device='cuda:0'), tensor([1000,  929], device='cuda:0'))\n",
      "Full rec. method (tensor([0, 3], device='cuda:0'), tensor([1040,  930], device='cuda:0'))\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 31.74 GiB total capacity; 8.74 GiB already allocated; 147.62 MiB free; 8.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo spike + reset\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m _, trial_type_nofb, _, spikes_nofb \u001b[38;5;241m=\u001b[39m \u001b[43mrun_with_perturbation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m tloss \u001b[38;5;241m=\u001b[39m trial_matched_mse(model, spikes_nofb_0, spikes_nofb)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m nloss \u001b[38;5;241m=\u001b[39m neuron_loss(model, spikes_nofb_0, spikes_nofb)\n",
      "File \u001b[0;32m/scratch/TrialMatchingBeyond/infopath/utils/functions.py:412\u001b[0m, in \u001b[0;36mrun_with_perturbation\u001b[0;34m(model, area, exc, trials, power, state, random_light, seed, thr, full_length)\u001b[0m\n\u001b[1;32m    410\u001b[0m model\u001b[38;5;241m.\u001b[39mrsnn\u001b[38;5;241m.\u001b[39msample_trial_noise(trials)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# spikes, _, _, _ = model(stims, light=light)\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m spikes, volt, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_with_dt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_spikes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m filt \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfilter_fun2(model\u001b[38;5;241m.\u001b[39mfilter_fun1(spikes))\n\u001b[1;32m    416\u001b[0m area0_active \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    417\u001b[0m     filt[:, :, model\u001b[38;5;241m.\u001b[39mrsnn\u001b[38;5;241m.\u001b[39marea_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmean((\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m model\u001b[38;5;241m.\u001b[39mtimestep\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;241m>\u001b[39m thr\n\u001b[1;32m    419\u001b[0m )\n",
      "File \u001b[0;32m/scratch/TrialMatchingBeyond/infopath/model_loader.py:158\u001b[0m, in \u001b[0;36mFullModel.step_with_dt\u001b[0;34m(self, input_spikes, state, mem_noise, light, dt)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m light \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     l \u001b[38;5;241m=\u001b[39m light[i \u001b[38;5;241m*\u001b[39m dt : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m dt]\n\u001b[0;32m--> 158\u001b[0m sp, v, j, state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_spikes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m spikes\u001b[38;5;241m.\u001b[39mappend(sp)\n\u001b[1;32m    160\u001b[0m voltages\u001b[38;5;241m.\u001b[39mappend(v)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/TrialMatchingBeyond/models/rsnn_nocond_nojawfeedback.py:754\u001b[0m, in \u001b[0;36mRSNN.forward\u001b[0;34m(self, input, state, light, seed, data)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# self.thr_rest_diff0 = thr0 - self.v_rest # from model in paper\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthr_rest_diff0 \u001b[38;5;241m=\u001b[39m thr0 \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_rest0\n\u001b[0;32m--> 754\u001b[0m mem_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem_noise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\n\u001b[1;32m    755\u001b[0m mem_noise \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthr_rest_diff \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigma_mem_noise \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 31.74 GiB total capacity; 8.74 GiB already allocated; 147.62 MiB free; 8.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['arial'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 234x155.26 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thr = 8\n",
    "trials, neurons = 2000, 500\n",
    "names = [\"base\", \"Full rec. method\", \"No sparsity\", \"Non-local inhibition\", \"No Dale's law\", \"No TM\", \"No spike\", \"Sigmoid\"]\n",
    "colors = [\"black\", \"blue\", \"red\", \"green\", \"purple\", \"orange\", \"brown\", \"pink\"]\n",
    "hypothesis = \"withfb1\"\n",
    "bins = np.linspace(-1, 2, 30)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "for hypothesis in [\"nofb\", \"withfb1\"]:\n",
    "    opt = load_training_opt(logs[hypothesis][0])\n",
    "    model_nofb = load_model_and_optimizer(opt, reload=True, last_best=\"best\")[0]\n",
    "\n",
    "    hit_miss_mean, hit_miss_var = np.zeros((8)), np.zeros((8))\n",
    "    tloss_mean, tloss_var = np.zeros((8)), np.zeros((8))\n",
    "    nloss_mean, nloss_var = np.zeros((8)), np.zeros((8))\n",
    "    filt = lambda x: model_nofb.filter_fun2(model_nofb.filter_fun1(x))\n",
    "    _, trial_type_nofb_0, _, spikes_nofb_0 = run_with_perturbation(model_nofb, trials=trials, area=0, exc=0, power=0, seed=0, thr=thr)\n",
    "    del model_nofb\n",
    "    fig_frdistro, ax_frdistro = plot_with_size(30, 20)\n",
    "    ax_frdistro.set_xscale(\"log\")\n",
    "    for i, log in enumerate(logs[hypothesis]):\n",
    "        opt = load_training_opt(log)\n",
    "        model = load_model_and_optimizer(opt, reload=True, last_best=\"best\")[0]\n",
    "        name = give_name(model.opt.log_path)\n",
    "        if name == \"No spike + reset\":\n",
    "            continue\n",
    "        _, trial_type_nofb, _, spikes_nofb = run_with_perturbation(model, trials=trials, area=0, exc=0, power=0, seed=2, thr=thr)\n",
    "        tloss = trial_matched_mse(model, spikes_nofb_0, spikes_nofb)[0]\n",
    "        nloss = neuron_loss(model, spikes_nofb_0, spikes_nofb)\n",
    "        fr_dist = spikes_nofb[:50].mean((0,1)) / model.timestep\n",
    "        # remove non-clear trials -- I do this for the No TM case, where you have a lot of intermediate trials\n",
    "        keep = torch.isin(trial_type_nofb, torch.tensor([0,3], device=trial_type_nofb.device))\n",
    "        trial_type_nofb = trial_type_nofb[keep]\n",
    "        hr = (trial_type_nofb==3)*1.\n",
    "        print(name, trial_type_nofb.unique(return_counts=True))\n",
    "        j = names.index(name)\n",
    "        div = 3 if name != \"base\" else 1\n",
    "        hit_miss_mean[j] += hr.mean().item() / div\n",
    "        hit_miss_var[j] += hr.var().item()\n",
    "        tloss_mean[j] += tloss.mean().item() / div\n",
    "        tloss_var[j] += tloss.var().item()\n",
    "        nloss_mean[j] += nloss.mean().item() / div\n",
    "        nloss_var[j] += nloss.var().item() \n",
    "        x, y = np.histogram(fr_dist.cpu().numpy().flatten(), bins=10**bins)\n",
    "        ax_frdistro.plot(y[:-1], x, color=colors[j], alpha=0.2)\n",
    "        del model\n",
    "    fig_hit, ax_hit = plot_with_size(20, 15)\n",
    "    for i in range(1, len(hit_miss_mean)):\n",
    "        ax_hit.errorbar(i-1, hit_miss_mean[i], yerr=1.96*np.sqrt(np.array(hit_miss_var)[i]/trials), fmt=\"o\", capsize=3, color=colors[i])\n",
    "    ax_hit.set_xticks(range(len(names)-1))\n",
    "    ax_hit.set_ylim(0.4, 0.8)\n",
    "    fig_hit.savefig(f\"FiguresOpto/Supplementary_Figure1/hit_{hypothesis}.pdf\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "    fig_psth, ax_psth = plot_with_size(30, 20)\n",
    "    for i in range(1, len(nloss_mean)):\n",
    "        ax_psth.errorbar(i-1, nloss_mean[i], yerr=1.96*np.sqrt(np.array(nloss_var)[i]/neurons), fmt=\"o\", capsize=3, color=colors[i])\n",
    "    ax_psth.set_xticks(range(len(names)-1))\n",
    "    fig_psth.savefig(f\"FiguresOpto/Supplementary_Figure1/psth_{hypothesis}.pdf\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "    fig_ttrial, ax_ttrial = plot_with_size(30, 20)\n",
    "    for i in range(1, len(tloss_mean)):\n",
    "        ax_ttrial.errorbar(i-1, tloss_mean[i], yerr=1.96*np.sqrt(np.array(tloss_var)[i]/trials), fmt=\"o\", capsize=3, color=colors[i])\n",
    "    ax_ttrial.set_xticks(range(len(names)-1))\n",
    "    fig_ttrial.savefig(f\"FiguresOpto/Supplementary_Figure1/ttrial_{hypothesis}.pdf\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "    fig_frdistro.savefig(f\"FiguresOpto/Supplementary_Figure1/frdistro_{hypothesis}.pdf\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "    if hypothesis == \"nofb\":\n",
    "        nloss_mean_nofb, nloss_std_nofb = nloss_mean, 1.96*np.sqrt(np.array(nloss_var)/neurons)\n",
    "        tloss_mean_nofb, tloss_std_nofb = tloss_mean, 1.96*np.sqrt(np.array(tloss_var)/neurons)\n",
    "    else:\n",
    "        nloss_mean_withfb1, nloss_std_withfb1 = nloss_mean, 1.96*np.sqrt(np.array(nloss_var)/neurons)\n",
    "        tloss_mean_withfb1, tloss_std_withfb1 = tloss_mean, 1.96*np.sqrt(np.array(tloss_var)/neurons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sem(x):\n",
    "    return x / np.sqrt(493)\n",
    "names = [\"base\", \"Full rec. method\", \"No sparsity\", \"Non-local inhibition\", \"No Dale's law\", \"No TM\", \"No spike\", \"Sigmoid\"]\n",
    "def latex_table(table_psth_pear_mean_nofb, table_psth_pear_std_nofb, table_psth_pear_mean_withfb, table_psth_pear_std_withfb):\n",
    "    for i in range(len(table_psth_pear_mean_nofb)):\n",
    "        print(f\"{names[i]} & {table_psth_pear_mean_nofb[i]:.2f} $\\pm$ {table_psth_pear_std_nofb[i]:.2f} & {table_psth_pear_mean_withfb[i]:.2f} $\\pm$ {table_psth_pear_std_withfb[i]:.2f} \\\\\\\\\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base & 0.18 $\\pm$ 0.02 & 0.17 $\\pm$ 0.02 \\\\\n",
      "Full rec. method & 0.25 $\\pm$ 0.05 & 0.25 $\\pm$ 0.05 \\\\\n",
      "No sparsity & 0.24 $\\pm$ 0.04 & 0.25 $\\pm$ 0.05 \\\\\n",
      "Non-local inhibition & 0.28 $\\pm$ 0.06 & 0.25 $\\pm$ 0.05 \\\\\n",
      "No Dale's law & 0.43 $\\pm$ 0.11 & 0.37 $\\pm$ 0.09 \\\\\n",
      "No TM & 0.23 $\\pm$ 0.04 & 0.22 $\\pm$ 0.04 \\\\\n",
      "No spike & 0.17 $\\pm$ 0.06 & 0.17 $\\pm$ 0.05 \\\\\n",
      "Sigmoid & 0.25 $\\pm$ 0.09 & 0.20 $\\pm$ 0.05 \\\\\n",
      "\n",
      "base & 0.25 $\\pm$ 0.01 & 0.26 $\\pm$ 0.01 \\\\\n",
      "Full rec. method & 0.27 $\\pm$ 0.02 & 0.28 $\\pm$ 0.02 \\\\\n",
      "No sparsity & 0.27 $\\pm$ 0.02 & 0.28 $\\pm$ 0.02 \\\\\n",
      "Non-local inhibition & 0.28 $\\pm$ 0.02 & 0.28 $\\pm$ 0.02 \\\\\n",
      "No Dale's law & 0.27 $\\pm$ 0.02 & 0.25 $\\pm$ 0.02 \\\\\n",
      "No TM & 0.68 $\\pm$ 0.04 & 0.54 $\\pm$ 0.04 \\\\\n",
      "No spike & 0.21 $\\pm$ 0.02 & 0.22 $\\pm$ 0.02 \\\\\n",
      "Sigmoid & 0.21 $\\pm$ 0.02 & 0.20 $\\pm$ 0.02 \\\\\n"
     ]
    }
   ],
   "source": [
    "# prepare code for latex table, where first column is the name of the method, second the mean plus minus sem of the pearson correlation of the psth nofb, and third the mean plus minus sem of the pearson correlation of the psth withfb\n",
    "def sem(x):\n",
    "    return x / np.sqrt(493)\n",
    "names = [\"base\", \"Full rec. method\", \"No sparsity\", \"Non-local inhibition\", \"No Dale's law\", \"No TM\", \"No spike\", \"Sigmoid\"]\n",
    "def latex_table(table_psth_pear_mean_nofb, table_psth_pear_std_nofb, table_psth_pear_mean_withfb, table_psth_pear_std_withfb):\n",
    "    for i in range(len(table_psth_pear_mean_nofb)):\n",
    "        print(f\"{names[i]} & {table_psth_pear_mean_nofb[i]:.2f} $\\pm$ {table_psth_pear_std_nofb[i]:.2f} & {table_psth_pear_mean_withfb[i]:.2f} $\\pm$ {table_psth_pear_std_withfb[i]:.2f} \\\\\\\\\")\n",
    "\n",
    "std = np.sqrt(np.array(nloss_var)[i]/neurons)\n",
    "latex_table(nloss_mean_nofb, nloss_std_nofb, nloss_mean_withfb1, nloss_std_withfb1)\n",
    "print(\"\")\n",
    "latex_table(tloss_mean_nofb, tloss_std_nofb, tloss_mean_withfb1, tloss_std_withfb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loss = True\n",
    "loss_ext = \"_loss\" if loss else \"\"\n",
    "df = pd.read_csv(f\"FiguresOpto/nofb_t_trial{loss_ext}.csv\")\n",
    "df1 = pd.read_csv(f\"FiguresOpto/withfb1_t_trial{loss_ext}.csv\")\n",
    "df = pd.concat([df, df1])\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Full rec. method\", \"Sigmoid\", \"No sparsity\", \"Non-local inhibition\", \"No Dale's law\", \"No TM\", \"No spike\"]\n",
    "tloss_mean_area0_light_nofb = []\n",
    "tloss_std_area0_light_nofb = []\n",
    "for name in names:\n",
    "    cond = (df[\"model_name\"] == name) & (df[\"power\"] >= 0.0) & (df[\"hypothesis\"] == \"nofb\") \n",
    "    tloss_mean_area0_light_nofb.append(df[cond][\"t_trial_21\"].mean())\n",
    "    tloss_std_area0_light_nofb.append(1.96 * (df[cond][\"t_trial_21\"].var()/3)**0.5)\n",
    "\n",
    "\n",
    "tloss_mean_area0_light_withfb1 = []\n",
    "tloss_std_area0_light_withfb1 = []\n",
    "for name in names:\n",
    "    cond = (df[\"model_name\"] == name) & (df[\"power\"] >= 0.0) & (df[\"hypothesis\"] == \"withfb1\") \n",
    "    tloss_mean_area0_light_withfb1.append(df[cond][\"t_trial_21\"].mean())\n",
    "    tloss_std_area0_light_withfb1.append(1.96 * (df[cond][\"t_trial_21\"].var()/3)**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base & 0.21 $\\pm$ 0.05 & 0.20 $\\pm$ 0.08 \\\\\n",
      "Full rec. method & 0.47 $\\pm$ 0.64 & 0.56 $\\pm$ 0.53 \\\\\n",
      "No sparsity & 0.48 $\\pm$ 0.79 & 0.19 $\\pm$ 0.06 \\\\\n",
      "Non-local inhibition & 0.37 $\\pm$ 0.31 & 0.68 $\\pm$ 0.69 \\\\\n",
      "No Dale's law & 0.41 $\\pm$ 0.31 & 0.84 $\\pm$ 1.11 \\\\\n",
      "No TM & 0.38 $\\pm$ 0.10 & 0.37 $\\pm$ 0.09 \\\\\n",
      "No spike & 0.18 $\\pm$ 0.02 & 0.26 $\\pm$ 0.15 \\\\\n"
     ]
    }
   ],
   "source": [
    "latex_table(tloss_mean_area0_light_nofb, tloss_std_area0_light_nofb, tloss_mean_area0_light_withfb1, tloss_std_area0_light_withfb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Full rec. method\", \"Sigmoid\", \"No sparsity\", \"Non-local inhibition\", \"No Dale's law\", \"No TM\", \"No spike\"]\n",
    "tloss_mean_area0_light_nofb = []\n",
    "tloss_std_area0_light_nofb = []\n",
    "for name in names:\n",
    "    cond = (df[\"model_name\"] == name) & (df[\"power\"] == 0.0) & (df[\"hypothesis\"] == \"nofb\") \n",
    "    tloss_mean_area0_light_nofb.append(df[cond][\"t_trial_21\"].mean())\n",
    "    tloss_std_area0_light_nofb.append(1.96 * (df[cond][\"t_trial_21\"].var()/3)**0.5)\n",
    "\n",
    "\n",
    "tloss_mean_area0_light_withfb1 = []\n",
    "tloss_std_area0_light_withfb1 = []\n",
    "for name in names:\n",
    "    cond = (df[\"model_name\"] == name) & (df[\"power\"] == 0.0) & (df[\"hypothesis\"] == \"withfb1\") \n",
    "    tloss_mean_area0_light_withfb1.append(df[cond][\"t_trial_21\"].mean())\n",
    "    tloss_std_area0_light_withfb1.append(1.96 * (df[cond][\"t_trial_21\"].var()/3)**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full rec. method & 0.19 $\\pm$ 0.01 & 0.18 $\\pm$ 0.01 \\\\\n",
      "Sigmoid & 0.16 $\\pm$ 0.01 & 0.17 $\\pm$ 0.01 \\\\\n",
      "No sparsity & 0.20 $\\pm$ 0.01 & 0.19 $\\pm$ 0.01 \\\\\n",
      "Non-local inhibition & 0.20 $\\pm$ 0.02 & 0.18 $\\pm$ 0.01 \\\\\n",
      "No Dale's law & 0.18 $\\pm$ 0.01 & 0.18 $\\pm$ 0.01 \\\\\n",
      "No TM & 0.33 $\\pm$ 0.01 & 0.35 $\\pm$ 0.03 \\\\\n",
      "No spike & 0.17 $\\pm$ 0.00 & 0.18 $\\pm$ 0.00 \\\\\n"
     ]
    }
   ],
   "source": [
    "latex_table(tloss_mean_area0_light_nofb, tloss_std_area0_light_nofb, tloss_mean_area0_light_withfb1, tloss_std_area0_light_withfb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bioRNN & 0.18 $\\pm$ 0.02 & 0.19 $\\pm$ 0.02 \\\\\n",
    "# $\\sigma$RNN & 0.16 $\\pm$ 0.02 & 0.16 $\\pm$ 0.02 \\\\\n",
    "# \\hline\n",
    "# No sparsity & 0.19 $\\pm$ 0.02 & 0.19 $\\pm$ 0.02 \\\\\n",
    "# Non-local inhibition & 0.19 $\\pm$ 0.02 & 0.18 $\\pm$ 0.02 \\\\\n",
    "# No Dale's law & 0.19 $\\pm$ 0.02 & 0.18 $\\pm$ 0.02 \\\\\n",
    "# No TM & 0.38 $\\pm$ 0.03 & 0.35 $\\pm$ 0.03 \\\\\n",
    "# No spike & 0.16 $\\pm$ 0.02 & 0.17 $\\pm$ 0.02 \\\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
