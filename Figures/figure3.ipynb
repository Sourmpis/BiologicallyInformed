{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infopath.model_loader import load_model_and_optimizer\n",
    "from infopath.config import load_training_opt,save_opt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from infopath.opto import opto_effect, light_generator, light_area\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from infopath.utils.functions import load_data\n",
    "from infopath.utils.functions import return_trial_type\n",
    "from infopath.utils.plot_utils import lick_prop_paper_like, lick_prop_with_ci, plot_with_size, strip_right_top_axis\n",
    "from infopath.lick_classifier import prepare_classifier\n",
    "from scipy.stats import ttest_ind\n",
    "import ast\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "font = {\"size\": 6, \"family\":\"arial\"}\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rc(\"font\", **font)\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_label(row):\n",
    "    if row.with_tm == 0:\n",
    "        return 4\n",
    "    if row.with_ei and not row.with_inh_across:\n",
    "        return 2\n",
    "    if not row.with_ei and row.with_inh_across:\n",
    "        return 3\n",
    "    if not row.with_ei and not row.with_inh_across:\n",
    "        if not row.with_spikes:\n",
    "            return 6\n",
    "        return -1\n",
    "    if not row.with_spikes:\n",
    "        return 5\n",
    "    if row.l1 == 0.02:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def model_version(log, step_size=400):\n",
    "    model_info = pd.read_table(f\"{log}/model_info.txt\", delimiter=\"      \", engine='python')\n",
    "    model_info.columns = [\"step\", \"name\"]\n",
    "    df = model_info.groupby(\"name\").max()\n",
    "    df = df.reset_index()\n",
    "    df.insert(2, \"step_id\", (df.step.values / 396).astype(\"int\"))\n",
    "    results = json.load(open(f\"{log}/results.json\", \"r\"))\n",
    "    last_step = (len(results[\"trial_type_accuracy\"])-1) * 400\n",
    "    max_trial_acc = np.max(results[\"trial_type_accuracy\"])\n",
    "    step_trial_type_and_t_trial = df[df.name.str.contains(\"best_trial_type_t_trial_ratio\")].step.values\n",
    "    if len(step_trial_type_and_t_trial) == 0:\n",
    "        model_v = \"best_trial_type\"\n",
    "        step = df[df.name==\"best_trial_type_model.ckpt\"].step.values[0]\n",
    "        return model_v, step, last_step\n",
    "    \n",
    "    actual_acc = results[\"trial_type_accuracy\"][step_trial_type_and_t_trial[0]//400]\n",
    "    if actual_acc == max_trial_acc:\n",
    "        model_v = \"best_trial_type_t_trial_ratio\"\n",
    "        step = step_trial_type_and_t_trial[0]\n",
    "    else:\n",
    "        model_v = \"best_trial_type\"\n",
    "        step = df[df.name==\"best_trial_type_model.ckpt\"].step.values[0]\n",
    "    return model_v, step, last_step\n",
    "\n",
    "def opto_figure(ax, dfs, area, color, label=\"\"):\n",
    "    star_table = np.zeros((3))\n",
    "    hit_rate_lines = []\n",
    "    fa_rate_lines = []\n",
    "    for j in (dfs.session.unique()[0:9]):\n",
    "        df = dfs[dfs.session == j]\n",
    "        hit, fa = lick_prop_paper_like(df, area, remove_control=False)\n",
    "        hit_rate_lines.append(hit)\n",
    "        fa_rate_lines.append(fa)\n",
    "    hit_rate_lines = np.array(hit_rate_lines)\n",
    "    fa_rate_lines = np.array(fa_rate_lines) \n",
    "    ax.set_ylim([0., 1])\n",
    "    ax.set_xticks([0, 1, 2, 3])\n",
    "    ax.set_xticklabels([\"Off\", \"W\", \"D\", \"R\"])\n",
    "    y = np.array(hit_rate_lines)\n",
    "    ax.plot(np.array(hit_rate_lines).mean(0), color=\"black\", linestyle=\"-\")\n",
    "    ax.errorbar(np.arange(4), y.mean(0), yerr=y.std(0)/y.shape[0]**0.5, color=f\"C{color}\", linestyle=\"-\", capsize=10, label=label)\n",
    "    for i in range(3):\n",
    "        star = ttest_ind(hit_rate_lines[:, i+1], hit_rate_lines[:, 0]).pvalue\n",
    "        star_table[i] = star\n",
    "        if star < 0.05/4:\n",
    "            ax.text(i+1, 0.7+0.05*color,  \"*\", color=f\"C{color}\", fontsize=20)\n",
    "    # ax.legend(loc=2)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    return ax, hit_rate_lines, fa_rate_lines, star_table\n",
    "\n",
    "std = lambda x, y: (x.var(2, ddof=1)/x.shape[2] + y.var(2, ddof=1)/y.shape[2])**0.5\n",
    "@torch.no_grad()\n",
    "def tune_power(model, powers, df_data, time_vector, lick_classifier, train_jaw, trials=200):\n",
    "    model.opt.batch_size = trials\n",
    "    time_vector = np.arange(model.T) * model.timestep + opt.start\n",
    "    tsts = np.zeros((len(powers), len(model.opt.areas)))\n",
    "    for i, power in enumerate(powers):\n",
    "        dfs = []\n",
    "        seeds = np.arange(0,2)\n",
    "        for seed in tqdm(seeds):    \n",
    "            torch.manual_seed(seed)\n",
    "            stims = torch.randint(2, size=(trials,)).to(model.opt.device)\n",
    "            state = model.steady_state()\n",
    "            input_spikes = model.input_spikes(stims)\n",
    "            model.rsnn.sample_mem_noise(model.T, trials)\n",
    "            mem_noise = model.rsnn.mem_noise.clone()\n",
    "            model.rsnn.sample_trial_noise(trials)\n",
    "            torch.manual_seed(seed)\n",
    "            spikes, _, jaw, _ = model.step_with_dt(input_spikes, state, mem_noise, dt=50) \n",
    "            filt_model = model.filter_fun1(spikes)\n",
    "            del spikes\n",
    "            torch.cuda.empty_cache()\n",
    "            df = opto_effect(\n",
    "                time_vector,\n",
    "                model.filter_fun1(train_spikes),\n",
    "                filt_model,\n",
    "                session_info_train,\n",
    "                model,\n",
    "                stims,\n",
    "                input_spikes,\n",
    "                state,\n",
    "                mem_noise,\n",
    "                filt_data_jaw=model.filter_fun1(train_jaw),\n",
    "                filt_jaw=model.filter_fun1(jaw),\n",
    "                lick_detector=lick_classifier,\n",
    "                response_time=response_time,\n",
    "                seed=seed,\n",
    "                verbose=False,\n",
    "                power=power,\n",
    "            )     \n",
    "            dfs.append(df)        \n",
    "        dfs = pd.concat(dfs, ignore_index=True)\n",
    "        dfs[\"session\"] = dfs.index.values // 24\n",
    "        hit_rate_data = dfdata_to_hitrate(df_data)\n",
    "        hit_rate_model = df_to_hitrate(dfs)\n",
    "        delta_hit_data = -(hit_rate_data[1:] - hit_rate_data[0])\n",
    "        delta_hit = -(hit_rate_model[1:] - hit_rate_model[0]) \n",
    "\n",
    "        tsts[i] = np.abs((delta_hit.mean(2) - delta_hit_data.mean(2))/std(delta_hit, delta_hit_data)).mean(0)\n",
    "    power = [powers[i] for i in np.abs(tsts).argmin(axis=0)]\n",
    "    print(power)\n",
    "    return power\n",
    "\n",
    "def df_to_hitrate(df):\n",
    "    hit_rate = np.zeros((df.period.nunique(), len(model.opt.areas), df.session.nunique()))\n",
    "    for j, period in enumerate(['off', 'whisker', 'delay', 'response']):\n",
    "        for i, area in enumerate(model.opt.areas):\n",
    "            for k, seed in enumerate(df.session.unique()):\n",
    "                prop = df[(df.area == area) & (df.period == period) & (df.session == seed)].propabilities.values[0]\n",
    "                hit_rate[j, i, k] = prop[1] / sum(prop[:2])\n",
    "    return hit_rate\n",
    "\n",
    "def dfsingle_to_hitrate(df):\n",
    "    hit_rate = np.zeros((df.period.nunique(), len(model.opt.areas)))\n",
    "    for j, period in enumerate(['off', 'whisker', 'delay', 'response']):\n",
    "        for i, area in enumerate(model.opt.areas):\n",
    "            prop = df[(df.area == area) & (df.period == period)].propabilities.values[0]\n",
    "            hit_rate[j, i] = prop[1] / sum(prop[:2])\n",
    "    return hit_rate\n",
    "\n",
    "\n",
    "def dfdata_to_hitrate(df, areas=[\"wS1\", \"wS2\", \"wM1\", \"wM2\", \"ALM\", \"tjM1\"]):\n",
    "    windows = [\"Control\", \"Stim\", \"Post\", \"Response\"]\n",
    "    hit_rate = np.zeros((len(windows), len(areas), df.mouse.nunique())) -1\n",
    "    for j, period in enumerate(windows):\n",
    "        for i, area in enumerate(areas):\n",
    "            for k, mouse in enumerate(df.mouse.unique()):\n",
    "                prop = df[(df.area == area) & (df.win == period) & (df.mouse == mouse)].groupby(\"mouse\").Hit.mean().values\n",
    "                hit_rate[j, i, k] = prop\n",
    "    return hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_total = [\n",
    "    # Full rec. model\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_17_14_54_10_l1across200_seed0\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_17_14_59_39_l1across200_seed1\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_17_14_59_37_l1across200_seed2\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_17_0_57_l1across200_seed3\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_17_3_20_l1across200_seed4\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_17_3_20_l1across200_seed5\",\n",
    "    # no sparsity\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_14_17_38_22_l1across0_seed0\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_14_19_49_19_l1across0_seed1\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_14_19_49_19_l1across0_seed2\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_16_57_43_l1across0_seed3\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_16_57_43_l1across0_seed4\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_17_0_57_l1across0_seed5\",\n",
    "    # no ei\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_24_14_32_2_l1across0_seed0\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_24_15_44_47_l1across0_seed1\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_24_15_17_51_l1across0_seed2\",\n",
    "    # no ei no across inh\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_12_28_36_l1across0_seed0\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_12_28_36_l1across0_seed1\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_12_28_36_l1across0_seed2\",\n",
    "    # no across inh \n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_8_17_45_l1across0_seed0\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_9_29_47_l1across0_seed1\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_19_9_29_45_l1across0_seed2\",\n",
    "    # no tm \n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_18_19_28_29_l1across0_seed0\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_18_17_39_17_l1across0_seed1\",\n",
    "    \"AllModels/61789467c93582ede80ee37bcf6ac8c1aa30e22a/2024_7_18_17_16_21_l1across0_seed2\",\n",
    "    # Full no spikes \n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_9_23_16_7_26_l1across200_seed0\",\n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_9_23_16_7_26_l1across200_seed1\",\n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_9_23_16_11_7_l1across200_seed2\",\n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_10_22_15_49_3_l1across200_seed3_nospike\",\n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_10_22_15_49_1_l1across200_seed4_nospike\",\n",
    "    # Sigma RNN\n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_10_24_17_3_25_l1across200_seed1\",\n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_10_24_17_3_25_l1across200_seed2\",\n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_10_24_17_3_25_l1across200_seed3\",\n",
    "    \"AllModels/37383bc21e52b1a427bf2086b0659664c2fc1ccc/2024_10_23_21_54_28_l1across200_seed4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "opt = load_training_opt(logs_total[0])\n",
    "opt.device = DEVICE\n",
    "model = load_model_and_optimizer(opt, reload=True, last_best=\"best_trial_type_t_trial_ratio\")[0]\n",
    "model.to(DEVICE)\n",
    "(\n",
    "    train_spikes,\n",
    "    train_jaw,\n",
    "    session_info_train,\n",
    "    test_spikes,\n",
    "    test_jaw,\n",
    "    session_info_test,ss\n",
    ") = load_data(model)\n",
    "filt = lambda x: model.filter_fun2(model.filter_fun1(x))\n",
    "response_time = 12\n",
    "lick_classifier = prepare_classifier(\n",
    "    filt(train_jaw),\n",
    "    filt(test_jaw),\n",
    "    session_info_train,\n",
    "    session_info_test,\n",
    "    DEVICE,\n",
    "    remove_mean=False,\n",
    "    response_time=response_time,\n",
    ")\n",
    "lick_classifier.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel 4A\n",
    "log_best = logs_total[1]\n",
    "log_path = log_best\n",
    "\n",
    "opt = load_training_opt(log_path)\n",
    "opt.device = DEVICE\n",
    "version, step, _ = model_version(log_best, \"\")\n",
    "model = load_model_and_optimizer(opt, reload=True, last_best=version)[0]\n",
    "time_vector = np.arange(model.T) * model.timestep + opt.start\n",
    "trials = 1000\n",
    "model.opt.batch_size = trials\n",
    "torch.manual_seed(1)\n",
    "with torch.no_grad():\n",
    "    stims = torch.ones(trials).to(model.opt.device)\n",
    "    stims[:trials//2] = 0\n",
    "    state = model.steady_state()\n",
    "    model.rsnn.sample_mem_noise(model.T, trials)\n",
    "    mem_noise = model.rsnn.mem_noise.clone()\n",
    "    spikes, _, jaw, _ = model.step_with_dt(\n",
    "        model.input_spikes(stims), \n",
    "        state, \n",
    "        mem_noise, \n",
    "        dt=50\n",
    "    )\n",
    "    filt_model = model.filter_fun1(spikes)\n",
    "    del spikes\n",
    "    filt_jaw = model.filter_fun1(jaw)\n",
    "    trial_types, model_perc = return_trial_type(\n",
    "        model, \n",
    "        model.filter_fun1(train_spikes), \n",
    "        filt_model, \n",
    "        model.filter_fun1(train_jaw), \n",
    "        filt_jaw, \n",
    "        session_info_train, \n",
    "        stims, \n",
    "        lick_classifier, \n",
    "        response_time=response_time,\n",
    "    )\n",
    "print(model_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel 4C\n",
    "response_time= 12\n",
    "opt = load_training_opt(log_path)\n",
    "opt.device = DEVICE\n",
    "time_vector = np.arange(model.T) * model.timestep + opt.start\n",
    "trials = 10\n",
    "model.opt.batch_size = trials\n",
    "torch.manual_seed(1)\n",
    "with torch.no_grad():\n",
    "    stims = torch.randint(2, size=(trials,)).to(model.opt.device)\n",
    "    state = model.steady_state()\n",
    "    model.rsnn.sample_mem_noise(model.T, trials)\n",
    "    mem_noise = model.rsnn.mem_noise.clone()\n",
    "    spikes, _, jaw, _ = model.step_with_dt(\n",
    "        model.input_spikes(stims), \n",
    "        state, \n",
    "        mem_noise, \n",
    "        dt=50\n",
    "    )\n",
    "    filt_model = model.filter_fun1(spikes)\n",
    "    filt_jaw = model.filter_fun1(jaw)\n",
    "    trial_types, model_perc = return_trial_type(\n",
    "        model, \n",
    "        model.filter_fun1(train_spikes), \n",
    "        filt_model, \n",
    "        model.filter_fun1(train_jaw), \n",
    "        filt_jaw, \n",
    "        session_info_train, \n",
    "        stims, \n",
    "        lick_classifier, \n",
    "        response_time=response_time,\n",
    "    )\n",
    "\n",
    "model.rsnn.light_neuron = (1-model.rsnn.excitatory_index.long()).bool()\n",
    "light, envelope = light_generator(time_vector, \"whisker\")\n",
    "envelope = model.filter_fun1(envelope[:, None, None])[:, 0, 0]\n",
    "light = light_area(light, model.opt.batch_size, model, 0)\n",
    "torch.manual_seed(1)\n",
    "with torch.no_grad():\n",
    "    stims = torch.randint(2, size=(trials,)).to(model.opt.device)\n",
    "    state = model.steady_state()\n",
    "    model.rsnn.sample_mem_noise(model.T, trials)\n",
    "    mem_noise = model.rsnn.mem_noise.clone()\n",
    "    spikes_light, _, jaw_light, _ = model.step_with_dt(\n",
    "        model.input_spikes(stims), \n",
    "        state, \n",
    "        mem_noise, \n",
    "        light=light * 0.15, \n",
    "        dt=50\n",
    "    )\n",
    "    filt_model = model.filter_fun1(spikes_light)\n",
    "    filt_jaw = model.filter_fun1(jaw_light)\n",
    "    trial_types_light, model_perc_light = return_trial_type(\n",
    "        model, \n",
    "        model.filter_fun1(train_spikes), \n",
    "        filt_model, \n",
    "        model.filter_fun1(train_jaw), \n",
    "        filt_jaw, \n",
    "        session_info_train, \n",
    "        stims, \n",
    "        lick_classifier, \n",
    "        response_time=response_time,\n",
    "    )\n",
    "filt_jaw = model.filter_fun2(model.filter_fun1(jaw))\n",
    "lick = lick_classifier(filt_jaw[-response_time:,:,0].T)\n",
    "filt_jaw_light = model.filter_fun2(model.filter_fun1(jaw_light))\n",
    "lick_light = lick_classifier(filt_jaw_light[-response_time:,:,0].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel 4C\n",
    "reposition = [(0, 200), (1200,1250), (200,400), (1250, 1300), (400, 600), (1300, 1350), (600, 800), (1350, 1400), (800, 1000), (1400, 1450), (1000, 1200), (1450, 1500)]\n",
    "r = []\n",
    "for r1 in reposition:\n",
    "    r.append([i for i in range(r1[0], r1[1])])\n",
    "r = np.concatenate(r)\n",
    "\n",
    "trial_to_check = 1\n",
    "filt_time = model.filter_fun1(torch.tensor(time_vector)[:, None,None])[:,0,0]\n",
    "color = np.array([\"black\", \"red\"])\n",
    "fig, ax = plot_with_size(60, 70)\n",
    "tsp, neurid = torch.where(spikes[:,trial_to_check,r].cpu())\n",
    "tsp = tsp * model.timestep + opt.start\n",
    "c = ((neurid % 250) > 200).long()\n",
    "ax.scatter(tsp, neurid, marker=\"|\", s=1, c=color[c], linewidth=0.5)\n",
    "ax.axvline(0, color=\"orange\")\n",
    "ax.axvline(1, color=\"black\")\n",
    "strip_right_top_axis(ax)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.set_xticklabels([\"\"])\n",
    "ax.set_yticklabels([\"\"])\n",
    "ax.set_yticks([])\n",
    "\n",
    "fig.savefig(\"Figures/Figure3/spikes.png\", bbox_inches=\"tight\", transparent=True, dpi=500)\n",
    "print(lick[trial_to_check], filt_jaw[:,trial_to_check].sum())\n",
    "fig, ax = plot_with_size(60, 30)\n",
    "ax.plot(filt_time, model.filter_fun1(jaw)[:,trial_to_check].cpu(), color=\"black\")\n",
    "ax.set_ylim(-0.2,6)\n",
    "fig.savefig(\"Figures/Figure3/jaw.pdf\", bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "fig, ax = plot_with_size(60, 70)\n",
    "tsp, neurid = torch.where(spikes_light[:,trial_to_check,r].cpu())\n",
    "tsp = tsp * model.timestep + opt.start\n",
    "c = ((neurid % 250) > 200).long()\n",
    "ax.scatter(tsp, neurid, marker=\"|\", s=1, c=color[c], linewidth=0.5)\n",
    "ax.axvline(0, color=\"orange\")\n",
    "ax.axvline(1, color=\"black\")\n",
    "strip_right_top_axis(ax)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.set_xticklabels([\"\"])\n",
    "ax.set_yticklabels([\"\"])\n",
    "ax.set_yticks([])\n",
    "fig.savefig(\"Figures/Figure3/spikes_light.png\", bbox_inches=\"tight\", transparent=True, dpi=500)\n",
    "print(lick_light[trial_to_check], filt_jaw_light[:,trial_to_check].sum())\n",
    "\n",
    "fig, ax = plot_with_size(60, 30)\n",
    "ax.plot(filt_time, model.filter_fun1(jaw_light)[:,trial_to_check].cpu(), color=\"black\")\n",
    "ax.set_ylim(-0.2,6)\n",
    "fig.savefig(\"Figures/Figure3/jaw_light.pdf\", dpi=300, bbox_inches=\"tight\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = lambda x, y: (x.var(2, ddof=1)/x.shape[2] + y.var(2, ddof=1)/y.shape[2])**0.5\n",
    "\n",
    "commit = \"\"\n",
    "df = pd.DataFrame(columns=[\"l1\",\"active_sun_across\", \"cosine\", \"abs_dist\", \"overlap\", \"tst\", \"t_trial_pearson_ratio\", \"with_ei\", \"with_inh_across\", \"with_tm\", \"log\", \"with_spikes\"])\n",
    "areas = [\"wS1\", \"wS2\", \"wM1\", \"wM2\", \"ALM\", \"tjM1\"]\n",
    "df_data = pd.read_csv(\"datasets/opto_data.csv\")\n",
    "num_mice_data = 9\n",
    "versions = [None for i in logs_total]\n",
    "k = 0\n",
    "for version, m in zip(versions, logs_total[:]):\n",
    "    opt = load_training_opt(f\"{m}\")\n",
    "    opt.device = DEVICE\n",
    "    if version is None:\n",
    "        version, step, _ = model_version(m, commit)\n",
    "    # model = load_model_and_optimizer(opt, reload=True, last_best=version)[0]\n",
    "    results = json.load(open(f\"{m}/results.json\", \"r\"))\n",
    "    t_trial_pearson_ratio = results[\"t_trial_pearson_ratio\"][step//400]\n",
    "    k+=1\n",
    "    # active_syn_diag = ((model.rsnn._w_rec[:, model.rsnn.off_diag].abs() > 1e-7).sum() / model.rsnn.off_diag.sum()).item()\n",
    "    dfs = pd.read_csv(f\"Figures/OptoEffect/opto_effect_{m.split('/')[-1]}.csv\")\n",
    "    dfs.propabilities = dfs.propabilities.apply(lambda s: list(ast.literal_eval(s)))\n",
    "    hit_effect = df_to_hitrate(dfs)\n",
    "    hit_effect_data = dfdata_to_hitrate(df_data)\n",
    "    delta_hit_data = -(hit_effect_data[1:] - hit_effect_data[0])\n",
    "    delta_hit = -(hit_effect[1:] - hit_effect[0]) \n",
    "    tst = (delta_hit.mean(2) - delta_hit_data.mean(2))/std(delta_hit, delta_hit_data)\n",
    "    s = hit_effect_data[0,:].flatten().std()\n",
    "    sensible = (hit_effect_data[1:].var(2, ddof=1)  < 1)\n",
    "    overlap = (np.abs(tst)<1.96).sum()\n",
    "    cos_sim = torch.cosine_similarity(torch.tensor(delta_hit_data.mean(2)).flatten(), torch.tensor(delta_hit.mean(2)).flatten(),dim=0).item()\n",
    "    abs_dist = (torch.tensor(delta_hit_data.mean(2)).flatten() - torch.tensor(delta_hit.mean(2)).flatten()).abs().mean().item()\n",
    "    with_spikes = True if opt.spike_function!=\"sigmoid\" else False \n",
    "    # print(f\"l1 across {opt.l1_decay_across}, active syn across {active_syn_diag:.3f}, cosine similarity: {cos_sim:.3f}, abs dist: {abs_dist:.3f}, overlap: {overlap} / {sensible.sum()}, seed {opt.seed}, tst {np.abs(tst).mean()}\")\n",
    "    # entry = {\"l1\":opt.l1_decay_across,\"active_sun_across\":active_syn_diag, \"cosine\":cos_sim, \"abs_dist\":abs_dist, \"overlap\":overlap, \"tst\":np.abs(tst).mean(), \"t_trial_pearson_ratio\": t_trial_pearson_ratio, \"with_ei\":opt.flag_ei, \"with_inh_across\":opt.restrict_inter_area_inh,\"with_tm\":opt.loss_trial_wise, \"log\":m.split(\"/\")[-1], \"with_spikes\":with_spikes}\n",
    "    entry = {\"l1\":opt.l1_decay_across, \"cosine\":cos_sim, \"abs_dist\":abs_dist, \"overlap\":overlap, \"tst\":np.abs(tst).mean(), \"t_trial_pearson_ratio\": t_trial_pearson_ratio, \"with_ei\":opt.flag_ei, \"with_inh_across\":opt.restrict_inter_area_inh,\"with_tm\":opt.loss_trial_wise, \"log\":m.split(\"/\")[-1], \"with_spikes\":with_spikes}\n",
    "    df = pd.concat([df, pd.DataFrame(entry, index=[0])], ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel 3e\n",
    "# Perturbations in wS1 and tjM1\n",
    "df_new = df#[df.t_trial_pearson_ratio > 0.88]\n",
    "df_panel4d = df_new[(df_new.l1 == 0) | (df_new.l1 == 0.02)]\n",
    "colors = [\"blue\", \"red\", \"green\", \"purple\", \"orange\", \"brown\", \"pink\"]\n",
    "\n",
    "xlabels = [\"Full\", \"No sparsity\", \"Inh across\", \"No Dale's law\", \"No TM\", \"No Spike\", \"Sigmoid\"]\n",
    "for area_id, area in enumerate(model.opt.areas):\n",
    "    label = []\n",
    "    delta_hit_rates = []\n",
    "    for i, row in enumerate(df_panel4d.iterrows()):\n",
    "        hit_rate = pd.read_csv(f\"Figures/OptoEffect/opto_effect_{row[-1].log}.csv\")\n",
    "        hit_rate.propabilities = hit_rate.propabilities.apply(lambda s: list(ast.literal_eval(s)))\n",
    "        hit_rate = df_to_hitrate(hit_rate).mean(2)\n",
    "        delta_hit_rates.append((hit_rate[1:] - hit_rate[0]))\n",
    "        label.append(give_label(row[1]))\n",
    "    df_panel4d[\"label\"] = label\n",
    "    delta_hit_rates = np.stack(delta_hit_rates, axis=2)\n",
    "\n",
    "    fig, ax = plot_with_size(60, 25)\n",
    "    strip_right_top_axis(ax)\n",
    "\n",
    "    points = pd.DataFrame(columns=(\"area\", \"delta_hit\", \"label\", \"period\"))\n",
    "    max_space = 0.3\n",
    "    interval_space = (max_space * 2) / len(colors)\n",
    "    for i in range(3):\n",
    "        # ax.scatter([i-max_space]*len(colors), -delta_hit_data[i,area_id], label=\"Data\", c=\"black\", alpha=0.3, s=5)\n",
    "        for k, j in enumerate(df_panel4d[\"label\"].values):\n",
    "            if (j == -1):\n",
    "                continue\n",
    "            # ax.scatter(i+(((j+1)*interval_space) - max_space), delta_hit_rates[i,area_id,k].mean(), c=colors[j], alpha=0.3, s=5)\n",
    "            entry = {\"area\":0, \"delta_hit\":delta_hit_rates[i,area_id,k].mean(), \"label\":j, \"period\":i}\n",
    "            points = pd.concat([points, pd.DataFrame(entry, index=[0])], ignore_index=True)\n",
    "\n",
    "        ax.errorbar(i-max_space, -delta_hit_data[i,area_id].mean(), yerr=delta_hit_data[i,area_id].std()/np.sqrt(9), fmt='o', c=\"black\", capsize=2, markersize=5)\n",
    "        for j in points.label.unique():\n",
    "            ax.errorbar(i+(((j+1)*interval_space) - max_space), points[(points.period == i) & (points.label == j)].delta_hit.mean(), yerr=points[(points.period == i) & (points.label == j)].delta_hit.std()/np.sqrt(points[(points.period == i) & (points.label == j)].shape[0]), fmt='o', c=colors[j], capsize=2, markersize=5)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_ylim(-0.65, 0.15)\n",
    "    ax.set_xticklabels([\"Whisker\", \"Delay\", \"Response\"])\n",
    "    ax.set_ylabel(\"Δ Lick propability\")\n",
    "    fig.savefig(f\"Figures/Figure3/panel3e_{area}.pdf\", bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel 3d\n",
    "# delta hit rate\n",
    "from infopath.utils.plot_utils import plot_with_size, strip_right_top_axis\n",
    "colors = [\"blue\", \"red\", \"green\", \"purple\", \"orange\", \"brown\", \"pink\"]\n",
    "\n",
    "df_new = df#[df.t_trial_pearson_ratio > 0.88]\n",
    "df_panel4e = df_new[(df_new.l1 == 0) | (df_new.l1 == 0.02)]\n",
    "\n",
    "\n",
    "fig, ax = plot_with_size(60, 25)\n",
    "strip_right_top_axis(ax)\n",
    "xlabels = [\"Full\", \"No sparsity\", \"Inh across\", \"No Dale's law\", \"No TM\", \"No Spike\", \"Sigmoid\"]\n",
    "label = []\n",
    "for i, row in enumerate(df_panel4e.iterrows()):\n",
    "    l = give_label(row[1])\n",
    "    label.append(l)\n",
    "\n",
    "df_panel4e[\"label\"] = label\n",
    "df_panel4e = df_panel4e[df_panel4e.label != -1]\n",
    "ax.scatter(df_panel4e.label, df_panel4e.abs_dist, c=np.array(colors)[df_panel4e.label], alpha=0.1)\n",
    "# mean = df_panel4e.groupby(\"label\").abs_dist.mean()\n",
    "# sem = df_panel4e.groupby(\"label\").abs_dist.std() / np.sqrt(df_panel4e.groupby(\"label\").abs_dist.count())\n",
    "for l in df_panel4e.label.unique():\n",
    "    mean = df_panel4e[df_panel4e.label == l].abs_dist.mean()\n",
    "    sem = df_panel4e[df_panel4e.label == l].abs_dist.std() / np.sqrt((df_panel4e.label == l).sum())\n",
    "    ax.errorbar(l, mean, yerr=sem, fmt='o', c=colors[l], capsize=3, marker=\"d\", markersize=5)\n",
    "ax.set_xticks(range(len(colors)))\n",
    "ax.set_xticklabels(xlabels)\n",
    "# rotate labels by 45 degrees\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "ax.set_ylabel(\"|Δp^D - Δ\\hat{p}|\")\n",
    "fig.savefig(\"Figures/Figure3/panel3d.pdf\", bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
